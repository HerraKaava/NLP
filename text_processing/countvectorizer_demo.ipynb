{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80ad5152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03757467",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/herrakaava/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/herrakaava/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/herrakaava/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0001dc19",
   "metadata": {},
   "source": [
    "<h3>Read in the data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e540b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/herrakaava/Desktop/Github_repos/NLP/data/bbc_text_cls.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "266cd5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    labels\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...  business"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "211d215e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2225 entries, 0 to 2224\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    2225 non-null   object\n",
      " 1   labels  2225 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 52.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ccaa5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text      False\n",
       "labels    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37fb3de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ad sales boost Time Warner profit\n",
      "\n",
      "Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier.\n",
      "\n",
      "The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.\n",
      "\n",
      "Time Warner said on Friday that it now owns 8% of search-engine Google. But its own internet business, AOL, had has mixed fortunes. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. However, the company said AOL's underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL's existing customers for high-speed broadband. TimeWarner also has to restate 2000 and 2003 results following a probe by the US Securities Exchange Commission (SEC), which is close to concluding.\n",
      "\n",
      "Time Warner's fourth quarter profits were slightly better than analysts' expectations. But its film division saw profits slump 27% to $284m, helped by box-office flops Alexander and Catwoman, a sharp contrast to year-earlier, when the third and final film in the Lord of the Rings trilogy boosted results. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. \"Our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility,\" chairman and chief executive Richard Parsons said. For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.\n",
      "\n",
      "TimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators. It has already offered to pay $300m to settle charges, in a deal that is under review by the SEC. The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann's purchase of a stake in AOL Europe, which it had reported as advertising revenue. It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.\n"
     ]
    }
   ],
   "source": [
    "# One document (row)\n",
    "print(df['text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd57764",
   "metadata": {},
   "source": [
    "<h3>Train-test split</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0e8d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db156771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "sport            0.229663\n",
       "business         0.229213\n",
       "politics         0.187416\n",
       "tech             0.180225\n",
       "entertainment    0.173483\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class distribution of the target\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f96d8de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61284033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (1780,)\n",
      "Shape of y_train: (1780,)\n",
      "\n",
      "Shape of X_test: (445,)\n",
      "Shape of y_test: (445,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of X_train: {X_train.shape}')\n",
    "print(f'Shape of y_train: {y_train.shape}')\n",
    "print()\n",
    "print(f'Shape of X_test: {X_test.shape}')\n",
    "print(f'Shape of y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be22359",
   "metadata": {},
   "source": [
    "<h3>CountVectorizer</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "979cb2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(Xtrain, Xtest, analyzer='word', stop_words=None):\n",
    "    vectorizer = CountVectorizer(analyzer=analyzer, stop_words=stop_words)\n",
    "    X_train_trans = vectorizer.fit_transform(Xtrain)\n",
    "    X_test_trans = vectorizer.transform(Xtest)\n",
    "    return X_train_trans, X_test_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "995302cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trans, X_test_trans = f(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6364d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1780, 26762)\n",
      "(445, 26762)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_trans.shape)\n",
    "print(X_test_trans.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ad5418",
   "metadata": {},
   "source": [
    "- The number of columns tells us that the *training corpus* consists of $\\, 26762 \\,$ unique words.\n",
    "- These $\\, 26762 \\,$ words form the *vocabulary* of the corpus.\n",
    "- Here we convert the text into vectors of numbers, where each number represents how many times each word of the vocabulary appears in each document (row)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb511488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train_trans))\n",
    "print(type(X_test_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "243ff218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7536029201223603)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of non-zero values\n",
    "((X_train_trans != 0).sum() / np.prod(X_train_trans.shape)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f35e0d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358989"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of non-zero values\n",
    "X_train_trans.nnz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493f99ce",
   "metadata": {},
   "source": [
    "<h3>Naive Bayes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a7e5306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9943820224719101\n",
      "Test accuracy: 0.9730337078651685\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train_trans, y_train)\n",
    "print(f'Training accuracy: {accuracy_score(y_train, model.predict(X_train_trans))}')\n",
    "print(f'Test accuracy: {accuracy_score(y_test, model.predict(X_test_trans))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0175735",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8308e3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9960674157303371\n",
      "Test accuracy: 0.9730337078651685\n"
     ]
    }
   ],
   "source": [
    "# With stopwords\n",
    "X_train_trans2, X_test_trans2 = f(X_train, X_test, stop_words='english')\n",
    "model2 = MultinomialNB()\n",
    "model2.fit(X_train_trans2, y_train)\n",
    "print(f'Training accuracy: {accuracy_score(y_train, model2.predict(X_train_trans2))}')\n",
    "print(f'Test accuracy: {accuracy_score(y_test, model2.predict(X_test_trans2))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aef9a60",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bbb96a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7098d8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "        \n",
    "    def __call__(self, document):\n",
    "        tokens = word_tokenize(document)\n",
    "        words_and_tags = nltk.pos_tag(tokens)\n",
    "        return [self.wnl.lemmatize(word, pos=get_wordnet_pos(tag)) for word, tag in words_and_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "956af7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/herrakaava/anaconda3/envs/nlp/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9932584269662922\n",
      "Test accuracy: 0.9730337078651685\n"
     ]
    }
   ],
   "source": [
    "# With lemmatization\n",
    "vectorizer3 = CountVectorizer(tokenizer=LemmaTokenizer())\n",
    "X_train_trans3 = vectorizer3.fit_transform(X_train)\n",
    "X_test_trans3 = vectorizer3.transform(X_test)\n",
    "model3 = MultinomialNB()\n",
    "model3.fit(X_train_trans3, y_train)\n",
    "print(f'Training accuracy: {accuracy_score(y_train, model3.predict(X_train_trans3))}')\n",
    "print(f'Test accuracy: {accuracy_score(y_test, model3.predict(X_test_trans3))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925971e9",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a443a0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StemTokenizer:\n",
    "    def __init__(self):\n",
    "        self.porter = PorterStemmer()\n",
    "        \n",
    "    def __call__(self, document):\n",
    "        tokens = word_tokenize(document)\n",
    "        return [self.porter.stem(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee9783ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/herrakaava/anaconda3/envs/nlp/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9921348314606742\n",
      "Test accuracy: 0.9730337078651685\n"
     ]
    }
   ],
   "source": [
    "# With stemming\n",
    "vectorizer4 = CountVectorizer(tokenizer=StemTokenizer())\n",
    "X_train_trans4 = vectorizer4.fit_transform(X_train)\n",
    "X_test_trans4 = vectorizer4.transform(X_test)\n",
    "model4 = MultinomialNB()\n",
    "model4.fit(X_train_trans4, y_train)\n",
    "print(f'Training accuracy: {accuracy_score(y_train, model4.predict(X_train_trans4))}')\n",
    "print(f'Test accuracy: {accuracy_score(y_test, model4.predict(X_test_trans4))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751a94b4",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6067388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenizer(s):\n",
    "    return s.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2463e5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9977528089887641\n",
      "Test accuracy: 0.9595505617977528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/herrakaava/anaconda3/envs/nlp/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# String split tokenizer\n",
    "vectorizer5 = CountVectorizer(tokenizer=simple_tokenizer)\n",
    "X_train_trans5 = vectorizer5.fit_transform(X_train)\n",
    "X_test_trans5 = vectorizer5.transform(X_test)\n",
    "model5 = MultinomialNB()\n",
    "model5.fit(X_trans_trans5, y_train)\n",
    "print(f'Training accuracy: {accuracy_score(y_train, model5.predict(X_train_trans5))}')\n",
    "print(f'Test accuracy: {accuracy_score(y_test, model5.predict(X_test_trans5))}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
