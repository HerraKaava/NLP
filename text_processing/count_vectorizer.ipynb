{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f517745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'This is the the the first document'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "64e48a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_list = s.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5d99f773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'This'),\n",
       " (1, 'is'),\n",
       " (2, 'the'),\n",
       " (3, 'the'),\n",
       " (4, 'the'),\n",
       " (5, 'first'),\n",
       " (6, 'document')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map each word to an index (to maintain order of the sentence)\n",
    "[(index, item) for index, item in enumerate(s_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc17572",
   "metadata": {},
   "source": [
    "<h3>Sklearn CountVectorizer</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c809f45e",
   "metadata": {},
   "source": [
    "[Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b2d900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "823362f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word')\n",
    "X = vectorizer.fit_transform([s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6c5649cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['document', 'first', 'is', 'the', 'this'], dtype=object)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5ccab0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 3, 1]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eabe477",
   "metadata": {},
   "source": [
    "- Counts the occurrences of each word in the \"document\" (well a single sentence in this case).\n",
    "- This is called tokenization of text (by default: lowercasing, splitting on whitespace, and removing punctuation).\n",
    "- Note that the order of the words is not preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bbf349",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ff7ffc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer2 = CountVectorizer(analyzer='char')\n",
    "X2 = vectorizer2.fit_transform(['Hi I am Marlon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "df8aac2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 2, 1, 2, 1, 2, 1, 1, 1]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9e04d3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' ', 'a', 'h', 'i', 'l', 'm', 'n', 'o', 'r'], dtype=object)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer2.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35b9d09",
   "metadata": {},
   "source": [
    "- If `analyzer='char'`, characters are counted instead of words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e932eb0",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee2d6483",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25be16fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer3 = CountVectorizer(analyzer='word')\n",
    "X3 = vectorizer3.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "686f68d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',\n",
       "       'this'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer3.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "193bbe82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
       "       [0, 2, 0, 1, 0, 1, 1, 0, 1],\n",
       "       [1, 0, 0, 1, 1, 0, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 0, 0, 1, 0, 1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f0234f",
   "metadata": {},
   "source": [
    "- Shows the occurrences of each word within each sentence (\"document\") in the rows.\n",
    "- Note that sklearn's CountVectorizer does not implement normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766ded09",
   "metadata": {},
   "source": [
    "<h3>Implement CountVectorizer manually</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ed4a0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d58671c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(row):\n",
    "    cleaned_sentence = []\n",
    "    for word in row:\n",
    "        # r in front of a string makes the string a raw string literal\n",
    "        # ==> all special characters (e.g., backslashes) are treated as literal characters\n",
    "        # (literal characters are characters that are interpreted exactly as typed)\n",
    "        cleaned_word = re.sub(pattern=r'[.,\\-_!?]', repl='', string=word).lower()\n",
    "        cleaned_sentence.append(cleaned_word)\n",
    "    return cleaned_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "accd9f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unique(cleaned_documents):\n",
    "    unique_words = []\n",
    "    for row in cleaned_documents:\n",
    "        for word in row:\n",
    "            if word not in unique_words:\n",
    "                unique_words.append(word)\n",
    "    return unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7ff9457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_occurrences(document, unique_words):\n",
    "    # Sorting the unique words is not necessary, but this way the output will match sklearn's\n",
    "    d = {word: 0 for word in sorted(unique_words)}\n",
    "    for word in document:\n",
    "        if word in d.keys():\n",
    "            d[word] += 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f301229a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['this', 'is', 'the', 'first', 'document'],\n",
       " ['this', 'document', 'is', 'the', 'second', 'document'],\n",
       " ['and', 'this', 'is', 'the', 'third', 'one'],\n",
       " ['is', 'this', 'the', 'first', 'document']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_documents = []\n",
    "for row in corpus:\n",
    "    cleaned_sentence = clean(row.split())\n",
    "    cleaned_documents.append(cleaned_sentence)\n",
    "cleaned_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8be8c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = count_unique(cleaned_documents)\n",
    "sorted(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37eeed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_array = np.zeros((len(cleaned_documents), len(unique_words)), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c26b7d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cleaned_documents)):\n",
    "    count = count_occurrences(cleaned_documents[i], unique_words)\n",
    "    counter_array[i, :] = list(count.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e49c8056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
       "       [0, 2, 0, 1, 0, 1, 1, 0, 1],\n",
       "       [1, 0, 0, 1, 1, 0, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 0, 0, 1, 0, 1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f154d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
       "       [0, 2, 0, 1, 0, 1, 1, 0, 1],\n",
       "       [1, 0, 0, 1, 1, 0, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 0, 0, 1, 0, 1]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing to sklearn CountVectorizer\n",
    "X3.toarray()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
